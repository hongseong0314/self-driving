{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f03deb7e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'globals'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-5c3438f9f7bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbinarization_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbinarize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mperspective_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbirdeye\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mline_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_fits_by_sliding_windows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdraw_back_onto_the_road\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_fits_by_previous_fits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmoviepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meditor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVideoFileClip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/yonggit/self-driving/yongjae/pr4_advanced lane detection/line_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbinarization_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbinarize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mperspective_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbirdeye\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mglobals\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mym_per_pix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxm_per_pix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'globals'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from calibration_utils import calibrate_camera, undistort\n",
    "from binarization_utils import binarize\n",
    "from perspective_utils import birdeye\n",
    "from line_utils import get_fits_by_sliding_windows, draw_back_onto_the_road, Line, get_fits_by_previous_fits\n",
    "from moviepy.editor import VideoFileClip\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "ym_per_pix = 30 / 720   # meters per pixel in y dimension\n",
    "xm_per_pix = 3.7 / 700  # meters per pixel in x dimension\n",
    "\n",
    "time_window = 10        # results are averaged over this number of frames\n",
    "\n",
    "\n",
    "processed_frames = 0                    # counter of frames processed (when processing video)\n",
    "line_lt = Line(buffer_len=time_window)  # line on the left of the lane\n",
    "line_rt = Line(buffer_len=time_window)  # line on the right of the lane\n",
    "\n",
    "\n",
    "def prepare_out_blend_frame(blend_on_road, img_binary, img_birdeye, img_fit, line_lt, line_rt, offset_meter):\n",
    "    \"\"\"\n",
    "    Prepare the final pretty pretty output blend, given all intermediate pipeline images\n",
    "\n",
    "    :param blend_on_road: color image of lane blend onto the road\n",
    "    :param img_binary: thresholded binary image\n",
    "    :param img_birdeye: bird's eye view of the thresholded binary image\n",
    "    :param img_fit: bird's eye view with detected lane-lines highlighted\n",
    "    :param line_lt: detected left lane-line\n",
    "    :param line_rt: detected right lane-line\n",
    "    :param offset_meter: offset from the center of the lane\n",
    "    :return: pretty blend with all images and stuff stitched\n",
    "    \"\"\"\n",
    "    h, w = blend_on_road.shape[:2]\n",
    "\n",
    "    thumb_ratio = 0.2\n",
    "    thumb_h, thumb_w = int(thumb_ratio * h), int(thumb_ratio * w)\n",
    "\n",
    "    off_x, off_y = 20, 15\n",
    "\n",
    "    # add a gray rectangle to highlight the upper area\n",
    "    mask = blend_on_road.copy()\n",
    "    mask = cv2.rectangle(mask, pt1=(0, 0), pt2=(w, thumb_h+2*off_y), color=(0, 0, 0), thickness=cv2.FILLED)\n",
    "    blend_on_road = cv2.addWeighted(src1=mask, alpha=0.2, src2=blend_on_road, beta=0.8, gamma=0)\n",
    "\n",
    "    # add thumbnail of binary image\n",
    "    thumb_binary = cv2.resize(img_binary, dsize=(thumb_w, thumb_h))\n",
    "    thumb_binary = np.dstack([thumb_binary, thumb_binary, thumb_binary]) * 255\n",
    "    blend_on_road[off_y:thumb_h+off_y, off_x:off_x+thumb_w, :] = thumb_binary\n",
    "\n",
    "    # add thumbnail of bird's eye view\n",
    "    thumb_birdeye = cv2.resize(img_birdeye, dsize=(thumb_w, thumb_h))\n",
    "    thumb_birdeye = np.dstack([thumb_birdeye, thumb_birdeye, thumb_birdeye]) * 255\n",
    "    blend_on_road[off_y:thumb_h+off_y, 2*off_x+thumb_w:2*(off_x+thumb_w), :] = thumb_birdeye\n",
    "\n",
    "    # add thumbnail of bird's eye view (lane-line highlighted)\n",
    "    thumb_img_fit = cv2.resize(img_fit, dsize=(thumb_w, thumb_h))\n",
    "    blend_on_road[off_y:thumb_h+off_y, 3*off_x+2*thumb_w:3*(off_x+thumb_w), :] = thumb_img_fit\n",
    "\n",
    "    # add text (curvature and offset info) on the upper right of the blend\n",
    "    mean_curvature_meter = np.mean([line_lt.curvature_meter, line_rt.curvature_meter])\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(blend_on_road, 'Curvature radius: {:.02f}m'.format(mean_curvature_meter), (860, 60), font, 0.9, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    cv2.putText(blend_on_road, 'Offset from center: {:.02f}m'.format(offset_meter), (860, 130), font, 0.9, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    return blend_on_road\n",
    "\n",
    "\n",
    "def compute_offset_from_center(line_lt, line_rt, frame_width):\n",
    "    \"\"\"\n",
    "    Compute offset from center of the inferred lane.\n",
    "    The offset from the lane center can be computed under the hypothesis that the camera is fixed\n",
    "    and mounted in the midpoint of the car roof. In this case, we can approximate the car's deviation\n",
    "    from the lane center as the distance between the center of the image and the midpoint at the bottom\n",
    "    of the image of the two lane-lines detected.\n",
    "\n",
    "    :param line_lt: detected left lane-line\n",
    "    :param line_rt: detected right lane-line\n",
    "    :param frame_width: width of the undistorted frame\n",
    "    :return: inferred offset\n",
    "    \"\"\"\n",
    "    if line_lt.detected and line_rt.detected:\n",
    "        line_lt_bottom = np.mean(line_lt.all_x[line_lt.all_y > 0.95 * line_lt.all_y.max()])\n",
    "        line_rt_bottom = np.mean(line_rt.all_x[line_rt.all_y > 0.95 * line_rt.all_y.max()])\n",
    "        lane_width = line_rt_bottom - line_lt_bottom\n",
    "        midpoint = frame_width / 2\n",
    "        offset_pix = abs((line_lt_bottom + lane_width / 2) - midpoint)\n",
    "        offset_meter = xm_per_pix * offset_pix\n",
    "    else:\n",
    "        offset_meter = -1\n",
    "\n",
    "    return offset_meter\n",
    "\n",
    "\n",
    "def process_pipeline(frame, keep_state=True):\n",
    "    \"\"\"\n",
    "    Apply whole lane detection pipeline to an input color frame.\n",
    "    :param frame: input color frame\n",
    "    :param keep_state: if True, lane-line state is conserved (this permits to average results)\n",
    "    :return: output blend with detected lane overlaid\n",
    "    \"\"\"\n",
    "\n",
    "    global line_lt, line_rt, processed_frames\n",
    "\n",
    "    # undistort the image using coefficients found in calibration\n",
    "    img_undistorted = undistort(frame, mtx, dist, verbose=False)\n",
    "\n",
    "    # binarize the frame s.t. lane lines are highlighted as much as possible\n",
    "    img_binary = binarize(img_undistorted, verbose=False)\n",
    "\n",
    "    # compute perspective transform to obtain bird's eye view\n",
    "    img_birdeye, M, Minv = birdeye(img_binary, verbose=False)\n",
    "\n",
    "    # fit 2-degree polynomial curve onto lane lines found\n",
    "    if processed_frames > 0 and keep_state and line_lt.detected and line_rt.detected:\n",
    "        line_lt, line_rt, img_fit = get_fits_by_previous_fits(img_birdeye, line_lt, line_rt, verbose=False)\n",
    "    else:\n",
    "        line_lt, line_rt, img_fit = get_fits_by_sliding_windows(img_birdeye, line_lt, line_rt, n_windows=9, verbose=False)\n",
    "\n",
    "    # compute offset in meter from center of the lane\n",
    "    offset_meter = compute_offset_from_center(line_lt, line_rt, frame_width=frame.shape[1])\n",
    "\n",
    "    # draw the surface enclosed by lane lines back onto the original frame\n",
    "    blend_on_road = draw_back_onto_the_road(img_undistorted, Minv, line_lt, line_rt, keep_state)\n",
    "\n",
    "    # stitch on the top of final output images from different steps of the pipeline\n",
    "    blend_output = prepare_out_blend_frame(blend_on_road, img_binary, img_birdeye, img_fit, line_lt, line_rt, offset_meter)\n",
    "\n",
    "    processed_frames += 1\n",
    "\n",
    "    return blend_output\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # first things first: calibrate the camera\n",
    "    ret, mtx, dist, rvecs, tvecs = calibrate_camera(calib_images_dir='camera_cal')\n",
    "\n",
    "    mode = 'images'\n",
    "\n",
    "    if mode == 'video':\n",
    "\n",
    "        selector = 'project'\n",
    "        clip = VideoFileClip('{}_video.mp4'.format(selector)).fl_image(process_pipeline)\n",
    "        clip.write_videofile('out_{}_{}.mp4'.format(selector, time_window), audio=False)\n",
    "\n",
    "    else:\n",
    "\n",
    "        test_img_dir = 'test_images'\n",
    "        for test_img in os.listdir(test_img_dir):\n",
    "\n",
    "            frame = cv2.imread(os.path.join(test_img_dir, test_img))\n",
    "\n",
    "            blend = process_pipeline(frame, keep_state=False)\n",
    "\n",
    "            cv2.imwrite('output_images/{}'.format(test_img), blend)\n",
    "\n",
    "            plt.imshow(cv2.cvtColor(blend, code=cv2.COLOR_BGR2RGB))\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08721c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
